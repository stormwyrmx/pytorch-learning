{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "# dir()就是查看当前模块的所有属性和方法，help()是查看函数或者模块的详细说明\n",
    "print(\"================tensor=================\")\n",
    "x = torch.arange(24)  # 一维张量，称之为向量\n",
    "print(type(x))\n",
    "print(x.shape)  # 等价于print(x.size()) 一维，长度为22\n",
    "print(x.numel())  # number of elements\n",
    "print(x.view(2, 3, 4))  # view是reshape的别名，reshape成2*3*4的矩阵\n",
    "print(x.reshape(3, 2, 4))  # reshape成3个2*4的矩阵（2*4的矩阵是2个4个元素的向量）\n",
    "\n",
    "print(torch.zeros(2, 3, 4))\n",
    "print(torch.zeros((2, 3, 4)))\n",
    "print(torch.ones(2, 3, 4))\n",
    "print(torch.tensor([[[1, 2, 3, 4], [3, 4, 2, 1], [4, 5, 6, 7]]]).shape)  # Channel 1,Height 3,Width 4。1层3行4列的矩阵\n",
    "print(torch.randn(3, 4))  # 生成一个3*4的矩阵，每个元素都是从标准正态分布中随机采样的"
   ],
   "id": "8d5bf9ebf6ed5b32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 对于任意具有相同形状的张量， 常见的标准算术运算符（+、-、*、/和**）都可以被升级为按元素运算\n",
    "print(\"================element-wise compute=================\")\n",
    "a=torch.tensor([[1.0,2,3],[4,5,6]])\n",
    "b=torch.tensor([[1,5,6],[7,8,9]])\n",
    "print(a+b)\n",
    "print(a-b)\n",
    "print(a*b)\n",
    "print(a/b)\n",
    "print(a**b)\n",
    "print(torch.exp(a))\n",
    "print(torch.cat((a,b),dim=0))  # concatenate 可以理解为，dim 的维度是从最外层“[”开始算的 ，如果是三维，dim=2才是将列进行合并。\n",
    "print(torch.cat((a,b),dim=1))  # 0 和 1 这种表示法与 .shape的结果是对应的，0代表沿着第0个维度，1代表沿着第1个维度\n",
    "print(a==b)  # 按照逻辑运算符的规则，返回一个布尔张量\n",
    "print(a.sum())  # 对张量中的所有元素进行求和，会产生一个单元素张量"
   ],
   "id": "327a0bb764fcda23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"================broadcasting=================\")\n",
    "c=torch.arange(2).reshape(2,1)\n",
    "d=torch.arange(3).reshape(1,3)\n",
    "print(c+d)"
   ],
   "id": "591a0fecfe503e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"================index and slice=================\")\n",
    "# 拿出来的都是第1个元素，只不过是二维所以是行\n",
    "print(a[1][2])  # 第1行第0列 It first selects the 1st row (a[1]), which is a tensor, and then selects the 2nd element of that row ([2]).\n",
    "print(a[1,2])  # 第1行第2列 This accesses the element at the 1st row and 2nd column directly in one step using a single indexing operation.\n",
    "print(a[0:2,0])  # 第0行到第2行（不包含第2行），第0列\n",
    "print(a[:,1:3])  # 第1列到第3列（不包含第3列）\n",
    "a[1,2]=9\n",
    "print(a)\n",
    "a[:,1:3]=555  # :表示沿轴0的所有元素\n",
    "print(a)"
   ],
   "id": "58f102e729f4d051",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T09:28:25.572318Z",
     "start_time": "2024-12-08T09:28:25.556749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"================saving memory=================\")\n",
    "print(id(a))\n",
    "c=a\n",
    "print(id(c))\n",
    "\n",
    "z=torch.zeros_like(a)\n",
    "print(id(z))\n",
    "z[:]=a+b\n",
    "print(z)\n",
    "print(id(z))\n",
    "\n",
    "print(id(a))\n",
    "a[:] = a + b  # 这里的[:]是指定a的所有元素，如果不加[:]，a的引用会指向新的对象，而不是原来的对象\n",
    "print(id(a))\n",
    "a+=b\n",
    "print(id(a))"
   ],
   "id": "ff12fd605cc1b0df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================saving memory=================\n",
      "2102198704064\n",
      "2102198704064\n",
      "2102198616528\n",
      "tensor([[  4., 570., 573.],\n",
      "        [ 25., 579., 582.]])\n",
      "2102198616528\n",
      "2102198704064\n",
      "2102198704064\n",
      "2102198704064\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T09:28:27.032816Z",
     "start_time": "2024-12-08T09:28:27.023362Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================conversion with numpy=================\n",
      "<class 'numpy.ndarray'>\n",
      "[[  5. 575. 579.]\n",
      " [ 32. 587. 591.]]\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[  5., 575., 579.],\n",
      "        [ 32., 587., 591.]])\n",
      "tensor([3.5000]) 3.5 3.5 3\n"
     ]
    }
   ],
   "execution_count": 8,
   "source": [
    "print(\"================conversion with numpy=================\")\n",
    "# tensor有数学上的概念，numpy只有计算机的概念\n",
    "a_numpy = a.numpy()\n",
    "print(type(a_numpy))\n",
    "print(a_numpy)\n",
    "a = torch.tensor(a_numpy)\n",
    "print(type(a))\n",
    "print(a)\n",
    "f=torch.tensor([3.5])\n",
    "print(f,f.item(),float(f),int(f))\n"
   ],
   "id": "1cc63ecf235ac6a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
